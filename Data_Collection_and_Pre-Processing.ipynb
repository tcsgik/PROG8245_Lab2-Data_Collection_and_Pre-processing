{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed3eb9a5",
   "metadata": {},
   "source": [
    "# Lab2 - Data Collection and Pre-processing\n",
    "\n",
    "## Data Requirements\n",
    "1. Purpose: Primary transactions file\n",
    "    -  Source: Any public e-commerce sample with ≥ 500 rows (e.g. the “1000 Sales Records” CSV on ExcelBIAnalytics¹ → keep first 500) OR the 500-row synthetic file created in class\n",
    "    - Notes: Must contain: date, customer_id, product, price, quantity, coupon_code (or promo field), shipping_city\n",
    "    - Reference source: https://excelbianalytics.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/\n",
    "    - Data source: Using some item of Reference source to generate primary_dataset.csv\n",
    "2. Purpose: Secondary metadata file\n",
    "    - Source: A second open data source of your choice (product catalogue, city look-ups, coupon descriptions, etc.)\n",
    "    - Notes: You will mine this file to build your Data Dictionary and (optionally) enhance features\n",
    "    - Data source: Using some item of Reference source to generate secondary_dataset.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b89274",
   "metadata": {},
   "source": [
    "## How to Generate coupon code in primary_dataset.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bcd1756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('Original_Dataset/primary_dataset.csv')\n",
    "\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Generate coupon code\n",
    "def generate_coupon_code():\n",
    "    return ''.join(random.choices(string.ascii_uppercase + string.digits, k=8))\n",
    "\n",
    "# Assign a coupon code to about 30% of rows, leave the rest as empty\n",
    "df['Coupon Code'] = [generate_coupon_code() if random.random() < 0.3 else '' for _ in range(len(df))]\n",
    "\n",
    "# Save new CSV file with the coupon codes\n",
    "df.to_csv('Original_Dataset/primary_dataset_with_CouponCode.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542d4b5",
   "metadata": {},
   "source": [
    "## Step 1: Hello, Data!\n",
    "Load primary_dataset_with_CouponCode.csv, display first 3 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7dcdad22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Order Date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Order ID",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Product",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Price",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Quantity",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Total Revenue",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "Shipping City",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Coupon Code",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "ref": "651335b2-52b3-42e7-9a08-d386bb1fbd54",
       "rows": [
        [
         "0",
         "10/18/2014",
         "686800706",
         "Cosmetics",
         "437.2",
         "8446",
         "3692591.2",
         "Medicine Hat",
         null
        ],
        [
         "1",
         "11/7/2011",
         "185941302",
         "Vegetables",
         "154.06",
         "3018",
         "464953.08",
         "Kingston",
         null
        ],
        [
         "2",
         "10/31/2016",
         "246222341",
         "Baby Food",
         "255.28",
         "1517",
         "387259.76",
         "Sudbury",
         null
        ]
       ],
       "shape": {
        "columns": 8,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order Date</th>\n",
       "      <th>Order ID</th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Total Revenue</th>\n",
       "      <th>Shipping City</th>\n",
       "      <th>Coupon Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/18/2014</td>\n",
       "      <td>686800706</td>\n",
       "      <td>Cosmetics</td>\n",
       "      <td>437.20</td>\n",
       "      <td>8446</td>\n",
       "      <td>3692591.20</td>\n",
       "      <td>Medicine Hat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/7/2011</td>\n",
       "      <td>185941302</td>\n",
       "      <td>Vegetables</td>\n",
       "      <td>154.06</td>\n",
       "      <td>3018</td>\n",
       "      <td>464953.08</td>\n",
       "      <td>Kingston</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/31/2016</td>\n",
       "      <td>246222341</td>\n",
       "      <td>Baby Food</td>\n",
       "      <td>255.28</td>\n",
       "      <td>1517</td>\n",
       "      <td>387259.76</td>\n",
       "      <td>Sudbury</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order Date   Order ID     Product   Price  Quantity  Total Revenue  \\\n",
       "0  10/18/2014  686800706   Cosmetics  437.20      8446     3692591.20   \n",
       "1   11/7/2011  185941302  Vegetables  154.06      3018      464953.08   \n",
       "2  10/31/2016  246222341   Baby Food  255.28      1517      387259.76   \n",
       "\n",
       "  Shipping City Coupon Code  \n",
       "0  Medicine Hat         NaN  \n",
       "1      Kingston         NaN  \n",
       "2       Sudbury         NaN  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('Original_Dataset/primary_dataset_with_CouponCode.csv')\n",
    "\n",
    "# Display first 3 rows\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec260a94",
   "metadata": {},
   "source": [
    "## Step 2: Pick the Right Container\n",
    "Depiction: Justify dict vs namedtuple vs class (1–2 sentences)\n",
    "\n",
    "Reason:\n",
    "I chose to use the class because the class can be flexible and easily expand a column, that convenient for future expansion and maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99f77d",
   "metadata": {},
   "source": [
    "## Step 3: Transaction Class and OO data structure\n",
    "Implement Transaction class and use it t populate an object-oriented data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "603928de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction details:\n",
      "Transaction(Order_Date=2025-02-01, Order_ID=202510017, Product=Vegetables, Price=100, Quantity=2, Total_Revenue=200, Shipping_City=Kitchener, Coupon_Code=SAVE10PS)\n"
     ]
    }
   ],
   "source": [
    "# Define a Transaction class\n",
    "class Transaction:\n",
    "    def __init__(self, Order_Date, Order_ID, Product, Price, Quantity, Total_Revenue, Shipping_City, Coupon_Code):\n",
    "        self.Order_Date = Order_Date\n",
    "        self.Order_ID = Order_ID\n",
    "        self.Product = Product\n",
    "        self.Price = Price\n",
    "        self.Quantity = Quantity\n",
    "        self.Total_Revenue = Total_Revenue\n",
    "        self.Shipping_City = Shipping_City\n",
    "        self.Coupon_Code = Coupon_Code\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return (f\"Transaction(Order_Date={self.Order_Date}, Order_ID={self.Order_ID}, Product={self.Product}, Price={self.Price}, \"\n",
    "                f\"Quantity={self.Quantity}, Total_Revenue={self.Total_Revenue}, Shipping_City={self.Shipping_City}, Coupon_Code={self.Coupon_Code})\")\n",
    "\n",
    "\n",
    "# Create a list of Transaction objects\n",
    "tx = Transaction(\n",
    "    Order_Date = \"2025-02-01\",\n",
    "    Order_ID = \"202510017\",\n",
    "    Product = \"Vegetables\",\n",
    "    Price = 100,\n",
    "    Quantity = 2,\n",
    "    Total_Revenue = 200,\n",
    "    Shipping_City = \"Kitchener\",\n",
    "    Coupon_Code = \"SAVE10PS\"\n",
    ")\n",
    "\n",
    "\n",
    "# Display the transaction\n",
    "print(\"Transaction details:\")\n",
    "print(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec9cdf9",
   "metadata": {},
   "source": [
    "## Step 4: Bulk Loader\n",
    "Using the primary_dataset_with_CouponCode.csv to do load_transactions() returning list ↦ type-hinted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44bedfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 transactions:\n",
      "Transaction(Order_Date=10/18/2014, Order_ID=686800706, Product=Cosmetics, Price=437.2, Quantity=8446, Total_Revenue=3692591.2, Shipping_City=Medicine Hat, Coupon_Code=nan)\n",
      "Transaction(Order_Date=11/7/2011, Order_ID=185941302, Product=Vegetables, Price=154.06, Quantity=3018, Total_Revenue=464953.08, Shipping_City=Kingston, Coupon_Code=nan)\n",
      "Transaction(Order_Date=10/31/2016, Order_ID=246222341, Product=Baby Food, Price=255.28, Quantity=1517, Total_Revenue=387259.76, Shipping_City=Sudbury, Coupon_Code=nan)\n",
      "Transaction(Order_Date=4/10/2010, Order_ID=161442649, Product=Cereal, Price=205.7, Quantity=3322, Total_Revenue=683335.4, Shipping_City=Red Deer, Coupon_Code=V8TEW8XI)\n",
      "Transaction(Order_Date=8/16/2011, Order_ID=645713555, Product=Fruits, Price=9.33, Quantity=9845, Total_Revenue=91853.85, Shipping_City=Brandon, Coupon_Code=nan)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from typing import List\n",
    "\n",
    "# Define load transactions function\n",
    "def load_transactions(filename: str) -> List[Transaction]:\n",
    "    df = pd.read_csv(filename)\n",
    "    # create a list of Transaction objects\n",
    "    transactions = [\n",
    "        Transaction(\n",
    "            row['Order Date'],\n",
    "            row['Order ID'],\n",
    "            row['Product'],\n",
    "            float(row['Price']),\n",
    "            int(row['Quantity']),\n",
    "            float(row['Total Revenue']),\n",
    "            row['Shipping City'],\n",
    "            row['Coupon Code']\n",
    "        )\n",
    "        for _, row in df.iterrows()\n",
    "    ]\n",
    "    return transactions\n",
    "    \n",
    "\n",
    "# Use bulk loader, call the function to load transactions list\n",
    "transactions = load_transactions('Original_Dataset/primary_dataset_with_CouponCode.csv')\n",
    "\n",
    "# Display the first 5 transactions\n",
    "print(\"First 5 transactions:\")\n",
    "\n",
    "for tx in transactions[:5]:\n",
    "    print(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c47676",
   "metadata": {},
   "source": [
    "## Step 5: Quick Profiling\n",
    "(1) Calculate the Min/mean/max price \n",
    "(2) Display unique city count and cities list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3c1074b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Price: 9.33\n",
      "Max Price: 668.27\n",
      "Mean Price: 274.29506\n",
      "unique cities count: 49\n",
      "cities list: {'Saskatoon', 'Lethbridge', 'Oshawa', 'Sudbury', 'Saint-Jean-sur-Richelieu', 'Moose Jaw', 'Brandon', 'Sarnia', 'Kamloops', 'Victoria', 'Drummondville', 'Toronto', 'Quebec City', 'Kingston', 'Halifax', 'Vancouver', 'Calgary', 'Abbotsford', 'Regina', 'Edmonton', 'Fredericton', 'Barrie', 'Brantford', 'Wood Buffalo', 'London', 'Red Deer', 'Peterborough', 'Grande Prairie', 'Saint John', 'Thunder Bay', 'Kelowna', 'Moncton', 'Hamilton', 'Belleville', 'New Westminster', 'Prince George', 'Vernon', 'Winnipeg', 'Montreal', 'Nanaimo', 'Chilliwack', 'Sherbrooke', 'Chatham-Kent', 'St. Catharines', 'Medicine Hat', 'Ottawa', 'Guelph', 'Kitchener', 'Windsor'}\n"
     ]
    }
   ],
   "source": [
    "# Get all list of Unit Prices\n",
    "prices = [tx.Price for tx in transactions]\n",
    "\n",
    "# Calculate min, mean, and max of Unit Prices\n",
    "min_price = min(prices)\n",
    "max_price = max(prices)\n",
    "mean_price = sum(prices) / len(prices)\n",
    "\n",
    "# Display the min, mean, and max of Unit Prices\n",
    "print(f\"Min Price: {min_price}\")\n",
    "print(f\"Max Price: {max_price}\")\n",
    "print(f\"Mean Price: {mean_price}\")\n",
    "\n",
    "# Get all list of Countrys(cities)\n",
    "cities = [tx.Shipping_City for tx in transactions]\n",
    "unique_cities = set(cities)\n",
    "print(f\"unique cities count: {len(unique_cities)}\")\n",
    "print(f\"cities list: {unique_cities}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24be8c1",
   "metadata": {},
   "source": [
    "## Step 6: Spot the Grime \n",
    "Identify at least three dirty data cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3a51596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing value of Coupon Code column: Transaction(Order_Date=10/18/2014, Order_ID=686800706, Product=Cosmetics, Price=437.2, Quantity=8446, Total_Revenue=3692591.2, Shipping_City=Medicine Hat, Coupon_Code=nan)\n",
      "missing value of Coupon Code column: Transaction(Order_Date=11/7/2011, Order_ID=185941302, Product=Vegetables, Price=154.06, Quantity=3018, Total_Revenue=464953.08, Shipping_City=Kingston, Coupon_Code=nan)\n",
      "missing value of Coupon Code column: Transaction(Order_Date=10/31/2016, Order_ID=246222341, Product=Baby Food, Price=255.28, Quantity=1517, Total_Revenue=387259.76, Shipping_City=Sudbury, Coupon_Code=nan)\n",
      "missing value of Coupon Code column: Transaction(Order_Date=8/16/2011, Order_ID=645713555, Product=Fruits, Price=9.33, Quantity=9845, Total_Revenue=91853.85, Shipping_City=Brandon, Coupon_Code=nan)\n",
      "missing value of Coupon Code column: Transaction(Order_Date=12/24/2013, Order_ID=118598544, Product=Vegetables, Price=154.06, Quantity=4800, Total_Revenue=739488.0, Shipping_City=Sudbury, Coupon_Code=nan)\n",
      "missing value of Coupon Code column: Transaction(Order_Date=2/27/2010, Order_ID=220003211, Product=Snacks, Price=152.58, Quantity=2694, Total_Revenue=411050.52, Shipping_City=Nanaimo, Coupon_Code=nan)\n",
      "\n",
      "All Product categories: {'Fruits', 'personal Care', 'office Supplies', 'Household', 'meat', 'Cosmetics', 'Beverages', 'Snacks', 'Office Supplies', 'Clothes', 'clothes', 'vegetables', 'Meat', 'fruits', 'snacks', 'Baby Food', 'beverages', 'Personal Care', 'Vegetables', 'Cereal', 'cereal'}\n",
      "\n",
      "\n",
      "No unreasonable values found in Units Sold or Unit Cost columns.\n"
     ]
    }
   ],
   "source": [
    "# Case 1: find missing values in the 'Coupon Code' column\n",
    "count = 0\n",
    "for tx in transactions:\n",
    "    if tx.Coupon_Code == '' or str(tx.Coupon_Code).lower() == 'nan':\n",
    "        print(\"missing value of Coupon Code column:\", tx)\n",
    "        count += 1\n",
    "        # only display 5 missing values\n",
    "        if count > 5:\n",
    "            break\n",
    "\n",
    "# Case 2: find inconsistent categories in 'Product' column, check inconsistent capitalization of words\n",
    "Product = set(tx.Product for tx in transactions)\n",
    "print(f\"\\nAll Product categories:\", Product)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Case 3: find impossible Values in Price and Total Revenue columns, if values are 0 or negative number\n",
    "found = False\n",
    "for tx in transactions:\n",
    "    if tx.Price <= 0:\n",
    "        print(\"Unreasonable Price:\", tx)\n",
    "        found = True\n",
    "    if tx.Total_Revenue <= 0:\n",
    "        print(\"Unreasonable Total_Revenue:\", tx)\n",
    "        found = True\n",
    "\n",
    "if not found:\n",
    "    print(\"No unreasonable values found in Units Sold or Unit Cost columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e74e5e",
   "metadata": {},
   "source": [
    "## Step 7: Cleaning Rules\n",
    "Execute fixes inside clean() and show “before/after” counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "72d4f602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Coupon Code before cleaning: 367, after cleaning: 0\n",
      "Negative Price before cleaning: 0, after cleaning: 0\n",
      "Negative Total Revenue before cleaning: 0, after cleaning: 0\n",
      "Inconsistent Product before cleaning: 9, after cleaning: 0\n"
     ]
    }
   ],
   "source": [
    "# Define a clean function\n",
    "def clean(transactions):\n",
    "    # The number of anomalies before statistical correction\n",
    "    before_missing_coupon_code = sum(\n",
    "        tx.Coupon_Code == '' or str(tx.Coupon_Code).lower() == 'nan'\n",
    "        for tx in transactions\n",
    "    )\n",
    "    before_negative_price = sum(\n",
    "        tx.Price <= 0 \n",
    "        for tx in transactions\n",
    "    )\n",
    "    before_negative_total_revenue = sum(\n",
    "        tx.Total_Revenue <= 0 \n",
    "        for tx in transactions\n",
    "    )\n",
    "    before_product = set(tx.Product for tx in transactions)\n",
    "    before_product_title = set(tx.Product.title() for tx in transactions)\n",
    "    before_inconsistent_product = len(before_product - before_product_title)\n",
    "\n",
    "\n",
    "    cleaned = []\n",
    "    for tx in transactions:\n",
    "        # Clean Coupon Code dataset\n",
    "        Coupon_Code = tx.Coupon_Code\n",
    "        if Coupon_Code == '' or str(Coupon_Code).lower() == 'nan':\n",
    "            Coupon_Code = 'NONE'\n",
    "        \n",
    "        # Clean Price dataset\n",
    "        Price = tx.Price if tx.Price > 0 else 0\n",
    "        \n",
    "        # Clean Total Revenue dataset\n",
    "        Total_Revenue = tx.Total_Revenue if tx.Total_Revenue > 0 else 0\n",
    "\n",
    "        # Clean Item Type dataset\n",
    "        Product = tx.Product.title() # \"vegetables\" -> \"Vegetables\"\n",
    "        \n",
    "        # Generate a new Transaction object with cleaned data\n",
    "        cleaned_tx = Transaction(\n",
    "            tx.Order_Date,\n",
    "            tx.Order_ID,\n",
    "            Product,\n",
    "            Price,\n",
    "            tx.Quantity,\n",
    "            Total_Revenue,\n",
    "            tx.Shipping_City,\n",
    "            Coupon_Code\n",
    "        )\n",
    "        cleaned.append(cleaned_tx)\n",
    "    \n",
    "    # The number of anomalies after statistical correction\n",
    "    after_missing_coupon_code = sum(\n",
    "        tx.Coupon_Code == '' or str(tx.Coupon_Code).lower() == 'nan'\n",
    "        for tx in cleaned\n",
    "    )\n",
    "    after_negative_price = sum(\n",
    "        tx.Price <= 0 \n",
    "        for tx in cleaned\n",
    "    )\n",
    "    after_negative_total_revenue = sum(\n",
    "        tx.Total_Revenue <= 0 \n",
    "        for tx in cleaned\n",
    "    )\n",
    "    after_product = set(tx.Product for tx in cleaned)\n",
    "    after_product_title = set(tx.Product.title() for tx in cleaned)\n",
    "    after_inconsistent_product = len(after_product - after_product_title)\n",
    "\n",
    "    # Print the number of anomalies before and after cleaning\n",
    "    print(f\"Missing Coupon Code before cleaning: {before_missing_coupon_code}, after cleaning: {after_missing_coupon_code}\")\n",
    "    print(f\"Negative Price before cleaning: {before_negative_price}, after cleaning: {after_negative_price}\")\n",
    "    print(f\"Negative Total Revenue before cleaning: {before_negative_total_revenue}, after cleaning: {after_negative_total_revenue}\")\n",
    "    print(f\"Inconsistent Product before cleaning: {before_inconsistent_product}, after cleaning: {after_inconsistent_product}\")\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "# Perform cleanup and display the number of exceptions before and after\n",
    "cleaned_transactions = clean(transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1a09a",
   "metadata": {},
   "source": [
    "## Step 8: Transformations\n",
    "Parse coupon_code ➞ numeric discount (others apply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2b1f0de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Order_Date': '10/18/2014', 'Order_ID': 686800706, 'Product': 'Cosmetics', 'Discounted_Price': 437.2, 'Quantity': 8446, 'Discounted_Total_Revenue': 3692591.2, 'Shipping_City': 'Medicine Hat', 'Coupon_Code': 'NONE', 'Discount': 0}\n",
      "{'Order_Date': '11/7/2011', 'Order_ID': 185941302, 'Product': 'Vegetables', 'Discounted_Price': 154.06, 'Quantity': 3018, 'Discounted_Total_Revenue': 464953.08, 'Shipping_City': 'Kingston', 'Coupon_Code': 'NONE', 'Discount': 0}\n",
      "{'Order_Date': '10/31/2016', 'Order_ID': 246222341, 'Product': 'Baby Food', 'Discounted_Price': 255.28, 'Quantity': 1517, 'Discounted_Total_Revenue': 387259.76, 'Shipping_City': 'Sudbury', 'Coupon_Code': 'NONE', 'Discount': 0}\n",
      "{'Order_Date': '4/10/2010', 'Order_ID': 161442649, 'Product': 'Cereal', 'Discounted_Price': 185.13, 'Quantity': 3322, 'Discounted_Total_Revenue': 615001.86, 'Shipping_City': 'Red Deer', 'Coupon_Code': 'V8TEW8XI', 'Discount': 0.1}\n",
      "{'Order_Date': '8/16/2011', 'Order_ID': 645713555, 'Product': 'Fruits', 'Discounted_Price': 9.33, 'Quantity': 9845, 'Discounted_Total_Revenue': 91853.85, 'Shipping_City': 'Brandon', 'Coupon_Code': 'NONE', 'Discount': 0}\n"
     ]
    }
   ],
   "source": [
    "# Coupon Code transformation to discount item\n",
    "def transform_with_discount(transactions):\n",
    "    coupon_to_discount = {\n",
    "        'NONE': 0,\n",
    "        'V8TEW8XI': 0.1,\n",
    "        'FYGS7TFE': 0.2,\n",
    "        'O0UFGU1G': 0.3,\n",
    "    }\n",
    "\n",
    "    transformed = []\n",
    "    for tx in transactions:\n",
    "        code = tx.Coupon_Code\n",
    "        # Default discount 5%\n",
    "        discount = coupon_to_discount.get(code, 0.05)\n",
    "\n",
    "        tx_dict = {\n",
    "            'Order_Date': tx.Order_Date,\n",
    "            'Order_ID': tx.Order_ID,\n",
    "            'Product': tx.Product,\n",
    "            'Discounted_Price': tx.Price * (1 - discount),\n",
    "            'Quantity': tx.Quantity,\n",
    "            'Discounted_Total_Revenue': tx.Total_Revenue * (1 - discount),\n",
    "            'Shipping_City': tx.Shipping_City,\n",
    "            'Coupon_Code': code,\n",
    "            'Discount': discount\n",
    "        }\n",
    "        transformed.append(tx_dict)\n",
    "\n",
    "    return transformed\n",
    "\n",
    "# Run the transformation\n",
    "transformed_transactions = transform_with_discount(cleaned_transactions)\n",
    "\n",
    "# Display the first 5 transformed transactions\n",
    "for tx in transformed_transactions[:5]:\n",
    "    print(tx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48081eb",
   "metadata": {},
   "source": [
    "## Step 9: Feature Engineering\n",
    "Add days_since_purchase feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c7b7ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Order_Date': '10/18/2014', 'Order_ID': 686800706, 'Product': 'Cosmetics', 'Discounted_Price': 437.2, 'Quantity': 8446, 'Discounted_Total_Revenue': 3692591.2, 'Shipping_City': 'Medicine Hat', 'Coupon_Code': 'NONE', 'Discount': 0, 'Days_Since_Purchase': 3875, 'Order_Month': 10, 'Order_Season': 'Fall'}\n",
      "{'Order_Date': '11/7/2011', 'Order_ID': 185941302, 'Product': 'Vegetables', 'Discounted_Price': 154.06, 'Quantity': 3018, 'Discounted_Total_Revenue': 464953.08, 'Shipping_City': 'Kingston', 'Coupon_Code': 'NONE', 'Discount': 0, 'Days_Since_Purchase': 4951, 'Order_Month': 11, 'Order_Season': 'Fall'}\n",
      "{'Order_Date': '10/31/2016', 'Order_ID': 246222341, 'Product': 'Baby Food', 'Discounted_Price': 255.28, 'Quantity': 1517, 'Discounted_Total_Revenue': 387259.76, 'Shipping_City': 'Sudbury', 'Coupon_Code': 'NONE', 'Discount': 0, 'Days_Since_Purchase': 3131, 'Order_Month': 10, 'Order_Season': 'Fall'}\n",
      "{'Order_Date': '4/10/2010', 'Order_ID': 161442649, 'Product': 'Cereal', 'Discounted_Price': 185.13, 'Quantity': 3322, 'Discounted_Total_Revenue': 615001.86, 'Shipping_City': 'Red Deer', 'Coupon_Code': 'V8TEW8XI', 'Discount': 0.1, 'Days_Since_Purchase': 5527, 'Order_Month': 4, 'Order_Season': 'Spring'}\n",
      "{'Order_Date': '8/16/2011', 'Order_ID': 645713555, 'Product': 'Fruits', 'Discounted_Price': 9.33, 'Quantity': 9845, 'Discounted_Total_Revenue': 91853.85, 'Shipping_City': 'Brandon', 'Coupon_Code': 'NONE', 'Discount': 0, 'Days_Since_Purchase': 5034, 'Order_Month': 8, 'Order_Season': 'Summer'}\n"
     ]
    }
   ],
   "source": [
    "# Importing the datetime module\n",
    "from datetime import datetime\n",
    "\n",
    "# Adding Days_Since_Purchase feature\n",
    "def transform_with_features(transactions):\n",
    "    transformed = []\n",
    "    today = datetime.today()\n",
    "    for tx in transactions:\n",
    "        order_date = datetime.strptime(tx['Order_Date'], \"%m/%d/%Y\")\n",
    "        # Calculate the number of days between Order_Date and today\n",
    "        days_since_purchase = (today - order_date).days\n",
    "\n",
    "        # Order month\n",
    "        order_month = order_date.month\n",
    "        # Order season\n",
    "        if order_month in [3, 4, 5]:\n",
    "            order_season = 'Spring'\n",
    "        elif order_month in [6, 7, 8]:\n",
    "            order_season = 'Summer'\n",
    "        elif order_month in [9, 10, 11]:\n",
    "            order_season = 'Fall'\n",
    "        else:\n",
    "            order_season = 'Winter'\n",
    "\n",
    "        # Create a dictionary with the transformed data\n",
    "        tx_dict = dict(tx)\n",
    "        tx_dict['Days_Since_Purchase'] = days_since_purchase\n",
    "        tx_dict['Order_Month'] = order_month\n",
    "        tx_dict['Order_Season'] = order_season\n",
    "\n",
    "        transformed.append(tx_dict)\n",
    "\n",
    "    return transformed\n",
    "\n",
    "# Run the transformation\n",
    "feature_transactions = transform_with_features(transformed_transactions)\n",
    "\n",
    "# Display the first 5 transformed transactions\n",
    "for tx in feature_transactions[:5]:\n",
    "    print(tx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b351856",
   "metadata": {},
   "source": [
    "## Step 10:  Mini-Aggregation\n",
    "Using dict or pandas.groupby to do revenue per shipping_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "faa4613d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics Revenue per Shipping City:\n",
      "Abbotsford: 20735089.43\n",
      "Barrie: 9057871.97\n",
      "Belleville: 16204929.47\n",
      "Brandon: 17338560.24\n",
      "Brantford: 14090030.35\n",
      "Calgary: 25993436.95\n",
      "Chatham-Kent: 13166902.21\n",
      "Chilliwack: 11110287.23\n",
      "Drummondville: 26545365.73\n",
      "Edmonton: 5261125.04\n",
      "Fredericton: 4612928.04\n",
      "Grande Prairie: 8672309.17\n",
      "Guelph: 6326587.35\n",
      "Halifax: 17792665.93\n",
      "Hamilton: 12243575.90\n",
      "Kamloops: 18822292.04\n",
      "Kelowna: 15064890.27\n",
      "Kingston: 14341253.22\n",
      "Kitchener: 16438319.84\n",
      "Lethbridge: 17941122.95\n",
      "London: 6000849.56\n",
      "Medicine Hat: 16730352.16\n",
      "Moncton: 36245925.07\n",
      "Montreal: 4479335.53\n",
      "Moose Jaw: 13319936.90\n",
      "Nanaimo: 7207241.24\n",
      "New Westminster: 10184535.69\n",
      "Oshawa: 22692123.85\n",
      "Ottawa: 5115256.46\n",
      "Peterborough: 8743041.35\n",
      "Prince George: 20893552.26\n",
      "Quebec City: 18509008.88\n",
      "Red Deer: 12897830.19\n",
      "Regina: 10982373.34\n",
      "Saint John: 6862793.62\n",
      "Saint-Jean-sur-Richelieu: 25225032.64\n",
      "Sarnia: 15453726.05\n",
      "Saskatoon: 7081022.71\n",
      "Sherbrooke: 14340324.62\n",
      "St. Catharines: 13860116.19\n",
      "Sudbury: 18009832.88\n",
      "Thunder Bay: 14196893.54\n",
      "Toronto: 16563356.98\n",
      "Vancouver: 16198457.74\n",
      "Vernon: 10117403.00\n",
      "Victoria: 18471386.72\n",
      "Windsor: 18591025.97\n",
      "Winnipeg: 7709918.48\n",
      "Wood Buffalo: 13276935.96\n"
     ]
    }
   ],
   "source": [
    "# Statistics revenue per Shipping City using python dict\n",
    "def calculate_revenue_per_cit(transactions):\n",
    "    revenue_by_city = {}\n",
    "    for tx in transactions:\n",
    "        city = tx['Shipping_City']  # Assuming 'Country' is the shipping city\n",
    "        revenue = tx['Discounted_Total_Revenue']\n",
    "        if city not in revenue_by_city:\n",
    "            revenue_by_city[city] = 0\n",
    "        revenue_by_city[city] += revenue\n",
    "    \n",
    "    return revenue_by_city\n",
    "\n",
    "# Calculate revenue per city\n",
    "revenue_per_city = calculate_revenue_per_cit(feature_transactions)\n",
    "\n",
    "# Display the revenue per city\n",
    "print(\"Statistics Revenue per Shipping City:\")\n",
    "for city, revenue in sorted(revenue_per_city.items()):\n",
    "    print(f\"{city}: {revenue:.2f}\")\n",
    "\n",
    "# Save revenue per Shipping City to a CSV file\n",
    "#import pandas as pd\n",
    "\n",
    "#df = pd.DataFrame(list(revenue_per_city.items()), columns=['City', 'Total Revenue'])\n",
    "#df = df.sort_values(by='Total Revenue', ascending=False) # Sort by Total Revenue from highest to lowest\n",
    "#df.to_csv('Organize_Dataset/total_revenue_by_city.csv', index=False, encoding='utf-8', float_format='%.2f')\n",
    "#print(\"Total Revenue by city saved to 'total_revenue_by_city.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2fac4",
   "metadata": {},
   "source": [
    "## Step 11: Serialization Checkpoint\n",
    "Save cleaned data(feature_transactions) to JSON and Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77b7db2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serialization checkpoint complete: CSV, JSON and Parquet saved.\n",
      "   Order_Date   Order_ID     Product  Discounted_Price  Quantity  \\\n",
      "0  10/18/2014  686800706   Cosmetics            437.20      8446   \n",
      "1   11/7/2011  185941302  Vegetables            154.06      3018   \n",
      "2  10/31/2016  246222341   Baby Food            255.28      1517   \n",
      "\n",
      "   Discounted_Total_Revenue Shipping_City Coupon_Code  Discount  \\\n",
      "0                3692591.20  Medicine Hat        NONE       0.0   \n",
      "1                 464953.08      Kingston        NONE       0.0   \n",
      "2                 387259.76       Sudbury        NONE       0.0   \n",
      "\n",
      "   Days_Since_Purchase  Order_Month Order_Season  \n",
      "0                 3875           10         Fall  \n",
      "1                 4951           11         Fall  \n",
      "2                 3131           10         Fall  \n",
      "\n",
      "\n",
      "   Order_Date   Order_ID     Product  Discounted_Price  Quantity  \\\n",
      "0  10/18/2014  686800706   Cosmetics            437.20      8446   \n",
      "1   11/7/2011  185941302  Vegetables            154.06      3018   \n",
      "2  10/31/2016  246222341   Baby Food            255.28      1517   \n",
      "\n",
      "   Discounted_Total_Revenue Shipping_City Coupon_Code  Discount  \\\n",
      "0                3692591.20  Medicine Hat        NONE       0.0   \n",
      "1                 464953.08      Kingston        NONE       0.0   \n",
      "2                 387259.76       Sudbury        NONE       0.0   \n",
      "\n",
      "   Days_Since_Purchase  Order_Month Order_Season  \n",
      "0                 3875           10         Fall  \n",
      "1                 4951           11         Fall  \n",
      "2                 3131           10         Fall  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(feature_transactions)\n",
    "\n",
    "# Round only float fields \n",
    "float_cols = df.select_dtypes(include=['float']).columns\n",
    "df[float_cols] = df[float_cols].round(2)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('Organize_Dataset/primary_dataset_with_CouponCode_Serialization.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Save the DataFrame to a JSON file\n",
    "df.to_json('Organize_Dataset/primary_dataset_with_CouponCode_Serialization.json', orient='records', force_ascii=False)\n",
    "\n",
    "# Save the DataFrame to a Parquet file\n",
    "df.to_parquet('Organize_Dataset/primary_dataset_with_CouponCode_Serialization.parquet', index=False)\n",
    "\n",
    "print(\"Serialization checkpoint complete: CSV, JSON and Parquet saved.\")\n",
    "\n",
    "# Load the JSON and Parquet files\n",
    "df_jaon = pd.read_json('Organize_Dataset/primary_dataset_with_CouponCode_Serialization.json')\n",
    "print(df_jaon.head(3))\n",
    "print(\"\\n\")\n",
    "\n",
    "df_parquet = pd.read_parquet('Organize_Dataset/primary_dataset_with_CouponCode_Serialization.parquet')\n",
    "print(df_parquet.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e287de",
   "metadata": {},
   "source": [
    "## Step 12: Soft Interview Reflection\n",
    "Explaining how OOP helped (< 120 words)\n",
    "\n",
    "Reason: When I use Object-Oriented Programming (OOP) to write my code, I can easily clean data, transform data items, and perform data feature engineering. This can display the dataset status clearly, making it easy to identify the data information and perform further data analysis. Also, OOP can reuse code efficiently and quickly maintain my code. Thus, I can focus on some functional requirements to modify the code at any time. On the other hand, OOP can improve code readability and extensibility. This helps me organize the data and analyze the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07e0cdb",
   "metadata": {},
   "source": [
    "## Data-Dictionary\n",
    "(1) Merge field definitions from the primary_dataset_with_CouponCode.csv header and the secondary_dataset.csv metadata source.\n",
    "(2) Present as a tidy Markdown table including the new columns, for example: Field, Type, Description, Source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "528f8a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Field | Type | Description | Source |\n",
      "|-------|------|-------------|--------|\n",
      "| Order Date | Date | Product order date | Primary CSV dataset |\n",
      "| Order ID | String | Product oroder ID | Primary CSV dataset |\n",
      "| Product | String | Product item | Primary CSV dataset |\n",
      "| Price | Float | Product price | Primary CSV dataset |\n",
      "| Quantity | Integer | Sell product number | Primary CSV dataset |\n",
      "| Total Revenue | Float | Product total revenue | Primary CSV dataset |\n",
      "| Shipping City | String | Shipping city of customer  | Primary CSV dataset |\n",
      "| Coupon Code | String | Product coupon code | Primary CSV dataset |\n",
      "| Province | String | Shipping province of customer  | Secondary metadata source |\n",
      "| Ship Date | Date | Product shipping date | Secondary metadata source |\n",
      "| Sales Channel | String | Shipping platform | Secondary metadata source |\n",
      "| Order Priority | String | Product order priority | Secondary metadata source |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the primary dataset fields\n",
    "primary_fields = pd.read_csv('Header_Dataset/primary_header.csv', delimiter='\\t')\n",
    "# Make sure the source field has a value. If there is no default value in the file, fill it with 'Primary'\n",
    "primary_fields['Source'] = primary_fields['Source'].fillna('Primary')\n",
    "# Added 'priority' field for merging priority\n",
    "primary_fields['priority'] = 1\n",
    "\n",
    "# Read the secondary metadata fields\n",
    "secondary_df = pd.read_csv('Header_Dataset/secondary_header.csv', delimiter='\\t')\n",
    "# If the field name is not 'Field', please adjust\n",
    "if 'Field' not in secondary_df.columns:\n",
    "    secondary_df = secondary_df.rename(columns={'Column': 'Field'})\n",
    "# Make sure the source field has a value. If there is no default value in the file, fill it with 'Secondary'\n",
    "secondary_df['Source'] = secondary_df['Source'].fillna('Secondary')\n",
    "# Added 'priority' field for merging priority\n",
    "secondary_df['priority'] = 2\n",
    "\n",
    "# Merge all primary and secondary fields\n",
    "all_merged_fields = pd.concat([primary_fields, secondary_df], ignore_index=True)\n",
    "\n",
    "# Sort by 'priority', then remove duplicate 'Field', keeping the higher priority items\n",
    "final_merged_data = all_merged_fields.sort_values(by='priority').drop_duplicates(subset=['Field'], keep='first')\n",
    "\n",
    "# Remove temporary 'priority' field\n",
    "final_merged_data = final_merged_data.drop(columns=['priority'])\n",
    "\n",
    "# If some fields are empty, fill in the missing Type and Description \n",
    "final_merged_data['Type'] = final_merged_data['Type'].fillna('Unknown')\n",
    "final_merged_data['Description'] = final_merged_data['Description'].fillna('No description')\n",
    "# Make sure the fields have values ​if some fields are empty\n",
    "final_merged_data['Source'] = final_merged_data['Source'].fillna('Unknown Source')\n",
    "\n",
    "# Check order of columns in the output table\n",
    "merged_table = final_merged_data[['Field', 'Type', 'Description', 'Source']]\n",
    "\n",
    "# Output Markdown table\n",
    "print(\"| Field | Type | Description | Source |\")\n",
    "print(\"|-------|------|-------------|--------|\")\n",
    "for _, row in merged_table.iterrows():\n",
    "    description = str(row['Description']).replace('\\n', ' ')\n",
    "    print(f\"| {row['Field']} | {row['Type']} | {description} | {row['Source']} |\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
